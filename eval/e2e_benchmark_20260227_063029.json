{
  "summary": {
    "generated_at": "2026-02-27T06:30:29.428900Z",
    "total_queries": 56,
    "successful_queries": 21,
    "failed_queries": 35,
    "timeout_failures": 2,
    "early_self_answer_exits": 0,
    "no_routing_output_cases": 0,
    "routing_accuracy_success_only_pct": 33.33,
    "avg_latency_s": 18.579,
    "avg_cost_usd": 0.024315,
    "total_cost_usd": 0.51062,
    "gpt5_baseline_per_query_usd": 0.012,
    "gpt5_baseline_total_usd_success_only": 0.252,
    "saved_vs_gpt5_total_usd_success_only": -0.25862
  },
  "results": [
    {
      "id": 1,
      "query": "Hello, how are you?",
      "expected": "groq/llama-3.1-8b-instant",
      "routed_model": "groq/llama-3.1-8b-instant",
      "routed_models": [
        "groq/llama-3.1-8b-instant"
      ],
      "used_models": [
        "groq/llama-3.1-8b-instant",
        "groq/llama-3.1-8b-instant"
      ],
      "correct_routing": true,
      "critical": false,
      "escalated": false,
      "latency_s": 2.024,
      "graph_latency_s": 1.444,
      "cost_usd": 2e-05,
      "saved_vs_gpt5_usd": 0.01198,
      "knn_top_score": 1.0,
      "flow_nodes": [
        "classifier",
        "knn_router",
        "worker"
      ],
      "can_self_answer": false,
      "failure_type": "",
      "error": "",
      "success": true
    },
    {
      "id": 2,
      "query": "What is the capital of Japan?",
      "expected": "groq/llama-3.1-8b-instant",
      "routed_model": "groq/llama-3.1-8b-instant",
      "routed_models": [
        "groq/llama-3.1-8b-instant"
      ],
      "used_models": [
        "groq/llama-3.1-8b-instant",
        "groq/llama-3.1-8b-instant"
      ],
      "correct_routing": true,
      "critical": false,
      "escalated": false,
      "latency_s": 0.941,
      "graph_latency_s": 0.53,
      "cost_usd": 1.9e-05,
      "saved_vs_gpt5_usd": 0.011981,
      "knn_top_score": 0.5766,
      "flow_nodes": [
        "classifier",
        "knn_router",
        "worker"
      ],
      "can_self_answer": false,
      "failure_type": "",
      "error": "",
      "success": true
    },
    {
      "id": 3,
      "query": "Who invented the telephone?",
      "expected": "groq/llama-3.1-8b-instant",
      "routed_model": "groq/llama-3.1-8b-instant",
      "routed_models": [
        "groq/llama-3.1-8b-instant"
      ],
      "used_models": [
        "groq/llama-3.1-8b-instant",
        "groq/llama-3.1-8b-instant"
      ],
      "correct_routing": true,
      "critical": false,
      "escalated": false,
      "latency_s": 1.505,
      "graph_latency_s": 0.655,
      "cost_usd": 2e-05,
      "saved_vs_gpt5_usd": 0.01198,
      "knn_top_score": 0.2488,
      "flow_nodes": [
        "classifier",
        "knn_router",
        "worker"
      ],
      "can_self_answer": false,
      "failure_type": "",
      "error": "",
      "success": true
    },
    {
      "id": 4,
      "query": "What does DNA stand for?",
      "expected": "groq/llama-3.1-8b-instant",
      "routed_model": "groq/llama-3.1-8b-instant",
      "routed_models": [
        "groq/llama-3.1-8b-instant"
      ],
      "used_models": [
        "groq/llama-3.1-8b-instant",
        "groq/llama-3.1-8b-instant"
      ],
      "correct_routing": true,
      "critical": false,
      "escalated": false,
      "latency_s": 1.233,
      "graph_latency_s": 0.722,
      "cost_usd": 1.9e-05,
      "saved_vs_gpt5_usd": 0.011981,
      "knn_top_score": 0.4096,
      "flow_nodes": [
        "classifier",
        "knn_router",
        "worker"
      ],
      "can_self_answer": false,
      "failure_type": "",
      "error": "",
      "success": true
    },
    {
      "id": 5,
      "query": "How many days are in a leap year?",
      "expected": "groq/llama-3.1-8b-instant",
      "routed_model": "gemini/gemini-2.5-flash",
      "routed_models": [
        "gemini/gemini-2.5-flash"
      ],
      "used_models": [
        "gemini/gemini-2.5-flash",
        "gemini/gemini-2.5-flash"
      ],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 3.47,
      "graph_latency_s": 2.475,
      "cost_usd": 0.000289,
      "saved_vs_gpt5_usd": 0.011711,
      "knn_top_score": 0.1998,
      "flow_nodes": [
        "classifier",
        "knn_router",
        "worker"
      ],
      "can_self_answer": false,
      "failure_type": "",
      "error": "",
      "success": true
    },
    {
      "id": 6,
      "query": "What is the largest ocean on Earth?",
      "expected": "groq/llama-3.1-8b-instant",
      "routed_model": "groq/llama-3.1-8b-instant",
      "routed_models": [
        "groq/llama-3.1-8b-instant"
      ],
      "used_models": [
        "groq/llama-3.1-8b-instant",
        "groq/llama-3.1-8b-instant"
      ],
      "correct_routing": true,
      "critical": false,
      "escalated": false,
      "latency_s": 1.43,
      "graph_latency_s": 1.015,
      "cost_usd": 2.5e-05,
      "saved_vs_gpt5_usd": 0.011975,
      "knn_top_score": 0.3515,
      "flow_nodes": [
        "classifier",
        "knn_router",
        "worker"
      ],
      "can_self_answer": false,
      "failure_type": "",
      "error": "",
      "success": true
    },
    {
      "id": 7,
      "query": "Who painted the Mona Lisa?",
      "expected": "groq/llama-3.1-8b-instant",
      "routed_model": "groq/llama-3.1-8b-instant",
      "routed_models": [
        "groq/llama-3.1-8b-instant"
      ],
      "used_models": [
        "groq/llama-3.1-8b-instant",
        "groq/llama-3.1-8b-instant"
      ],
      "correct_routing": true,
      "critical": false,
      "escalated": false,
      "latency_s": 2.559,
      "graph_latency_s": 2.02,
      "cost_usd": 1.9e-05,
      "saved_vs_gpt5_usd": 0.011981,
      "knn_top_score": 0.2836,
      "flow_nodes": [
        "classifier",
        "knn_router",
        "worker"
      ],
      "can_self_answer": false,
      "failure_type": "",
      "error": "",
      "success": true
    },
    {
      "id": 8,
      "query": "What is the speed of light?",
      "expected": "groq/llama-3.1-8b-instant",
      "routed_model": "groq/llama-3.1-8b-instant",
      "routed_models": [
        "groq/llama-3.1-8b-instant"
      ],
      "used_models": [
        "groq/llama-3.1-8b-instant",
        "groq/llama-3.1-8b-instant"
      ],
      "correct_routing": true,
      "critical": false,
      "escalated": false,
      "latency_s": 1.321,
      "graph_latency_s": 0.853,
      "cost_usd": 2.2e-05,
      "saved_vs_gpt5_usd": 0.011978,
      "knn_top_score": 0.2373,
      "flow_nodes": [
        "classifier",
        "knn_router",
        "worker"
      ],
      "can_self_answer": false,
      "failure_type": "",
      "error": "",
      "success": true
    },
    {
      "id": 9,
      "query": "Define entropy in one sentence.",
      "expected": "groq/llama-3.1-8b-instant",
      "routed_model": "cerebras/gpt-oss-120b",
      "routed_models": [
        "cerebras/gpt-oss-120b"
      ],
      "used_models": [
        "cerebras/gpt-oss-120b",
        "cerebras/gpt-oss-120b"
      ],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 1.312,
      "graph_latency_s": 0.904,
      "cost_usd": 0.00013,
      "saved_vs_gpt5_usd": 0.01187,
      "knn_top_score": 0.4666,
      "flow_nodes": [
        "classifier",
        "knn_router",
        "worker"
      ],
      "can_self_answer": false,
      "failure_type": "",
      "error": "",
      "success": true
    },
    {
      "id": 10,
      "query": "Write a Python function to merge two sorted arrays.",
      "expected": "groq/kimi-k2",
      "routed_model": "groq/moonshotai/kimi-k2-instruct-0905",
      "routed_models": [
        "groq/moonshotai/kimi-k2-instruct-0905"
      ],
      "used_models": [
        "groq/moonshotai/kimi-k2-instruct-0905",
        "groq/moonshotai/kimi-k2-instruct-0905"
      ],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.522,
      "graph_latency_s": 2.072,
      "cost_usd": 9.9e-05,
      "saved_vs_gpt5_usd": 0.011901,
      "knn_top_score": 0.5232,
      "flow_nodes": [
        "classifier",
        "knn_router",
        "worker"
      ],
      "can_self_answer": false,
      "failure_type": "",
      "error": "",
      "success": true
    },
    {
      "id": 11,
      "query": "Implement a stack using linked lists in Java.",
      "expected": "groq/kimi-k2",
      "routed_model": "openrouter/anthropic/claude-opus-4.6",
      "routed_models": [
        "openrouter/anthropic/claude-opus-4.6",
        "groq/moonshotai/kimi-k2-instruct-0905"
      ],
      "used_models": [
        "openrouter/anthropic/claude-opus-4.6",
        "groq/moonshotai/kimi-k2-instruct-0905",
        "openrouter/anthropic/claude-opus-4.6",
        "groq/moonshotai/kimi-k2-instruct-0905"
      ],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 36.816,
      "graph_latency_s": 35.919,
      "cost_usd": 0.147197,
      "saved_vs_gpt5_usd": -0.135197,
      "knn_top_score": 0.3942,
      "flow_nodes": [
        "classifier",
        "knn_router",
        "parallel_workers",
        "aggregator"
      ],
      "can_self_answer": false,
      "failure_type": "",
      "error": "",
      "success": true
    },
    {
      "id": 12,
      "query": "Debug this TypeScript function that returns undefined.",
      "expected": "groq/kimi-k2",
      "routed_model": "groq/moonshotai/kimi-k2-instruct-0905",
      "routed_models": [
        "groq/moonshotai/kimi-k2-instruct-0905",
        "openrouter/anthropic/claude-opus-4.6",
        "openrouter/anthropic/claude-opus-4.6"
      ],
      "used_models": [
        "groq/moonshotai/kimi-k2-instruct-0905",
        "openrouter/anthropic/claude-opus-4.6",
        "openrouter/anthropic/claude-opus-4.6",
        "groq/moonshotai/kimi-k2-instruct-0905",
        "openrouter/anthropic/claude-opus-4.6",
        "openrouter/anthropic/claude-opus-4.6"
      ],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 46.72,
      "graph_latency_s": 45.693,
      "cost_usd": 0.18872,
      "saved_vs_gpt5_usd": -0.17672,
      "knn_top_score": 0.4127,
      "flow_nodes": [
        "classifier",
        "knn_router",
        "parallel_workers",
        "aggregator"
      ],
      "can_self_answer": false,
      "failure_type": "",
      "error": "",
      "success": true
    },
    {
      "id": 13,
      "query": "Write unit tests for a REST API endpoint using pytest.",
      "expected": "groq/kimi-k2",
      "routed_model": "openrouter/anthropic/claude-opus-4.6",
      "routed_models": [
        "openrouter/anthropic/claude-opus-4.6",
        "groq/moonshotai/kimi-k2-instruct-0905",
        "openrouter/anthropic/claude-opus-4.6"
      ],
      "used_models": [
        "openrouter/anthropic/claude-opus-4.6",
        "groq/moonshotai/kimi-k2-instruct-0905",
        "openrouter/anthropic/claude-opus-4.6",
        "openrouter/anthropic/claude-opus-4.6",
        "groq/moonshotai/kimi-k2-instruct-0905",
        "openrouter/anthropic/claude-opus-4.6"
      ],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 39.039,
      "graph_latency_s": 37.834,
      "cost_usd": 0.003897,
      "saved_vs_gpt5_usd": 0.008103,
      "knn_top_score": 0.4505,
      "flow_nodes": [
        "classifier",
        "knn_router",
        "parallel_workers",
        "aggregator"
      ],
      "can_self_answer": false,
      "failure_type": "",
      "error": "",
      "success": true
    },
    {
      "id": 14,
      "query": "Create a React hook for debounced search.",
      "expected": "groq/kimi-k2",
      "routed_model": "groq/moonshotai/kimi-k2-instruct-0905",
      "routed_models": [
        "groq/moonshotai/kimi-k2-instruct-0905",
        "openrouter/anthropic/claude-opus-4.6"
      ],
      "used_models": [
        "groq/moonshotai/kimi-k2-instruct-0905",
        "openrouter/anthropic/claude-opus-4.6",
        "groq/moonshotai/kimi-k2-instruct-0905",
        "openrouter/anthropic/claude-opus-4.6"
      ],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 34.555,
      "graph_latency_s": 33.684,
      "cost_usd": 0.000835,
      "saved_vs_gpt5_usd": 0.011165,
      "knn_top_score": 0.3815,
      "flow_nodes": [
        "classifier",
        "knn_router",
        "parallel_workers",
        "aggregator"
      ],
      "can_self_answer": false,
      "failure_type": "",
      "error": "",
      "success": true
    },
    {
      "id": 15,
      "query": "Implement the observer pattern in Python.",
      "expected": "groq/kimi-k2",
      "routed_model": "openrouter/anthropic/claude-opus-4.6",
      "routed_models": [
        "openrouter/anthropic/claude-opus-4.6",
        "groq/moonshotai/kimi-k2-instruct-0905"
      ],
      "used_models": [
        "openrouter/anthropic/claude-opus-4.6",
        "groq/moonshotai/kimi-k2-instruct-0905",
        "openrouter/anthropic/claude-opus-4.6",
        "groq/moonshotai/kimi-k2-instruct-0905"
      ],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 36.068,
      "graph_latency_s": 35.149,
      "cost_usd": 0.00308,
      "saved_vs_gpt5_usd": 0.00892,
      "knn_top_score": 0.4119,
      "flow_nodes": [
        "classifier",
        "knn_router",
        "parallel_workers",
        "aggregator"
      ],
      "can_self_answer": false,
      "failure_type": "",
      "error": "",
      "success": true
    },
    {
      "id": 16,
      "query": "Write a SQL query to find the second highest salary.",
      "expected": "groq/kimi-k2",
      "routed_model": "gemini/gemini-2.5-flash",
      "routed_models": [
        "gemini/gemini-2.5-flash"
      ],
      "used_models": [
        "gemini/gemini-2.5-flash",
        "gemini/gemini-2.5-flash"
      ],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 17.215,
      "graph_latency_s": 16.823,
      "cost_usd": 0.008685,
      "saved_vs_gpt5_usd": 0.003315,
      "knn_top_score": 0.5878,
      "flow_nodes": [
        "classifier",
        "knn_router",
        "worker"
      ],
      "can_self_answer": false,
      "failure_type": "",
      "error": "",
      "success": true
    },
    {
      "id": 17,
      "query": "Convert this Python 2 code to Python 3.",
      "expected": "groq/kimi-k2",
      "routed_model": "gemini/gemini-2.5-flash",
      "routed_models": [
        "gemini/gemini-2.5-flash",
        "groq/llama-3.1-8b-instant",
        "groq/moonshotai/kimi-k2-instruct-0905",
        "gemini/gemini-2.5-flash",
        "groq/moonshotai/kimi-k2-instruct-0905",
        "gemini/gemini-2.5-flash",
        "groq/moonshotai/kimi-k2-instruct-0905",
        "gemini/gemini-2.5-flash"
      ],
      "used_models": [
        "gemini/gemini-2.5-flash",
        "groq/llama-3.1-8b-instant",
        "groq/moonshotai/kimi-k2-instruct-0905",
        "gemini/gemini-2.5-flash",
        "groq/moonshotai/kimi-k2-instruct-0905",
        "gemini/gemini-2.5-flash",
        "groq/moonshotai/kimi-k2-instruct-0905",
        "gemini/gemini-2.5-flash",
        "gemini/gemini-2.5-flash",
        "groq/llama-3.1-8b-instant",
        "groq/moonshotai/kimi-k2-instruct-0905",
        "gemini/gemini-2.5-flash",
        "groq/moonshotai/kimi-k2-instruct-0905",
        "gemini/gemini-2.5-flash",
        "groq/moonshotai/kimi-k2-instruct-0905",
        "gemini/gemini-2.5-flash"
      ],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 46.882,
      "graph_latency_s": 43.843,
      "cost_usd": 0.041305,
      "saved_vs_gpt5_usd": -0.029305,
      "knn_top_score": 0.3636,
      "flow_nodes": [
        "classifier",
        "knn_router",
        "parallel_workers",
        "aggregator"
      ],
      "can_self_answer": false,
      "failure_type": "",
      "error": "",
      "success": true
    },
    {
      "id": 18,
      "query": "Write a basic web scraper in Python using BeautifulSoup.",
      "expected": "groq/kimi-k2",
      "routed_model": "groq/moonshotai/kimi-k2-instruct-0905",
      "routed_models": [
        "groq/moonshotai/kimi-k2-instruct-0905",
        "groq/moonshotai/kimi-k2-instruct-0905"
      ],
      "used_models": [
        "groq/moonshotai/kimi-k2-instruct-0905",
        "groq/moonshotai/kimi-k2-instruct-0905",
        "groq/moonshotai/kimi-k2-instruct-0905",
        "groq/moonshotai/kimi-k2-instruct-0905"
      ],
      "correct_routing": false,
      "critical": true,
      "escalated": false,
      "latency_s": 15.404,
      "graph_latency_s": 14.724,
      "cost_usd": 0.006673,
      "saved_vs_gpt5_usd": 0.005327,
      "knn_top_score": 0.2694,
      "flow_nodes": [
        "classifier",
        "knn_router",
        "parallel_workers",
        "aggregator",
        "judge"
      ],
      "can_self_answer": false,
      "failure_type": "",
      "error": "",
      "success": true
    },
    {
      "id": 19,
      "query": "Compare the pros and cons of electric vs hydrogen cars.",
      "expected": "groq/gpt-oss-120b",
      "routed_model": "cerebras/gpt-oss-120b",
      "routed_models": [
        "cerebras/gpt-oss-120b",
        "cerebras/gpt-oss-120b"
      ],
      "used_models": [
        "cerebras/gpt-oss-120b",
        "cerebras/gpt-oss-120b",
        "cerebras/gpt-oss-120b",
        "cerebras/gpt-oss-120b"
      ],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 24.115,
      "graph_latency_s": 23.312,
      "cost_usd": 0.013773,
      "saved_vs_gpt5_usd": -0.001773,
      "knn_top_score": 0.2844,
      "flow_nodes": [
        "classifier",
        "knn_router",
        "parallel_workers",
        "aggregator"
      ],
      "can_self_answer": false,
      "failure_type": "",
      "error": "",
      "success": true
    },
    {
      "id": 20,
      "query": "Explain how blockchain consensus mechanisms work.",
      "expected": "groq/gpt-oss-120b",
      "routed_model": "cerebras/gpt-oss-120b",
      "routed_models": [
        "cerebras/gpt-oss-120b"
      ],
      "used_models": [
        "cerebras/gpt-oss-120b",
        "cerebras/gpt-oss-120b"
      ],
      "correct_routing": false,
      "critical": true,
      "escalated": false,
      "latency_s": 36.473,
      "graph_latency_s": 36.042,
      "cost_usd": 0.018248,
      "saved_vs_gpt5_usd": -0.006248,
      "knn_top_score": 0.337,
      "flow_nodes": [
        "classifier",
        "knn_router",
        "parallel_workers",
        "aggregator",
        "judge"
      ],
      "can_self_answer": false,
      "failure_type": "",
      "error": "",
      "success": true
    },
    {
      "id": 21,
      "query": "What are the key differences between agile and waterfall?",
      "expected": "groq/gpt-oss-120b",
      "routed_model": "cerebras/gpt-oss-120b",
      "routed_models": [
        "cerebras/gpt-oss-120b",
        "openrouter/anthropic/claude-opus-4.6"
      ],
      "used_models": [
        "cerebras/gpt-oss-120b",
        "openrouter/anthropic/claude-opus-4.6",
        "cerebras/gpt-oss-120b",
        "openrouter/anthropic/claude-opus-4.6"
      ],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 38.555,
      "graph_latency_s": 37.782,
      "cost_usd": 0.077545,
      "saved_vs_gpt5_usd": -0.065545,
      "knn_top_score": 0.3834,
      "flow_nodes": [
        "classifier",
        "knn_router",
        "parallel_workers",
        "aggregator"
      ],
      "can_self_answer": false,
      "failure_type": "",
      "error": "",
      "success": true
    },
    {
      "id": 22,
      "query": "Explain the model-view-controller architecture pattern.",
      "expected": "groq/gpt-oss-120b",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 60.115,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "benchmark_timeout",
      "error": "query_timeout>60.0s",
      "success": false
    },
    {
      "id": 23,
      "query": "Describe how DNS resolution works step by step.",
      "expected": "groq/gpt-oss-120b",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 60.046,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "benchmark_timeout",
      "error": "query_timeout>60.0s",
      "success": false
    },
    {
      "id": 24,
      "query": "Compare Docker and virtual machines.",
      "expected": "groq/gpt-oss-120b",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.675,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 25,
      "query": "What are the trade-offs of eventual consistency?",
      "expected": "groq/gpt-oss-120b",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.706,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 26,
      "query": "How does HTTPS encryption work?",
      "expected": "groq/gpt-oss-120b",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.723,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 27,
      "query": "Explain the difference between threads and processes.",
      "expected": "groq/gpt-oss-120b",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.935,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 28,
      "query": "Analyze the economic impact of AI on the labor market in 2025.",
      "expected": "cerebras/qwen3-235b",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.693,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 29,
      "query": "Write a comprehensive overview of mRNA vaccine technology.",
      "expected": "cerebras/qwen3-235b",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.714,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 30,
      "query": "Explain the geopolitical implications of semiconductor supply chains.",
      "expected": "cerebras/qwen3-235b",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.569,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 31,
      "query": "Provide a deep analysis of central bank digital currencies.",
      "expected": "cerebras/qwen3-235b",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.629,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 32,
      "query": "Summarize the evolution of machine learning from 1950 to present.",
      "expected": "cerebras/qwen3-235b",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.926,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 33,
      "query": "Analyze the sociological effects of social media on Gen Z.",
      "expected": "cerebras/qwen3-235b",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.812,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 34,
      "query": "Write a literature review on attention mechanisms in NLP.",
      "expected": "cerebras/qwen3-235b",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.716,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 35,
      "query": "Compare the education systems of Finland, Japan, and the US.",
      "expected": "cerebras/qwen3-235b",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.691,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 36,
      "query": "Is it safe to combine metformin and alcohol?",
      "expected": "openai/gpt-4o",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.679,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 37,
      "query": "What are my rights if wrongfully terminated in Texas?",
      "expected": "openai/gpt-4o",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.726,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 38,
      "query": "Explain the tax implications of selling inherited property.",
      "expected": "openai/gpt-4o",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.795,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 39,
      "query": "What are the warning signs of a stroke?",
      "expected": "openai/gpt-4o",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.658,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 40,
      "query": "Review this non-compete clause for enforceability issues.",
      "expected": "openai/gpt-4o",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.802,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 41,
      "query": "What are the fiduciary duties of a board of directors?",
      "expected": "openai/gpt-4o",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.592,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 42,
      "query": "Explain HIPAA compliance requirements for a web app.",
      "expected": "openai/gpt-4o",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.561,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 43,
      "query": "What are the side effects of long-term statin use?",
      "expected": "openai/gpt-4o",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.601,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 44,
      "query": "Solve for x: 5x^2 - 3x + 2 = 0.",
      "expected": "gemini/gemini-2.5-flash",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.912,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 45,
      "query": "What is the derivative of ln(x^2 + 1)?",
      "expected": "gemini/gemini-2.5-flash",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.629,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 46,
      "query": "Calculate compound interest: $5000 at 4% for 10 years.",
      "expected": "gemini/gemini-2.5-flash",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.678,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 47,
      "query": "Convert 250 kilometers per hour to miles per hour.",
      "expected": "gemini/gemini-2.5-flash",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.839,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 48,
      "query": "Find the eigenvalues of matrix [[2,1],[1,2]].",
      "expected": "gemini/gemini-2.5-flash",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.942,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 49,
      "query": "Integrate x*e^x dx.",
      "expected": "gemini/gemini-2.5-flash",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.914,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 50,
      "query": "Compute the probability of rolling sum 7 with two dice.",
      "expected": "gemini/gemini-2.5-flash",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.742,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 51,
      "query": "Write production JWT auth middleware with refresh tokens for Express.",
      "expected": "openrouter/anthropic/claude-opus-4.6",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.546,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 52,
      "query": "Design a scalable event-driven payment processing system.",
      "expected": "openrouter/anthropic/claude-opus-4.6",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.881,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 53,
      "query": "Perform a security audit on this REST API implementation.",
      "expected": "openrouter/anthropic/claude-opus-4.6",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.672,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 54,
      "query": "Implement distributed locking with Redis and proper failover.",
      "expected": "openrouter/anthropic/claude-opus-4.6",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.837,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 55,
      "query": "Write a complete CI/CD pipeline for Kubernetes deployment.",
      "expected": "openrouter/anthropic/claude-opus-4.6",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.8,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    },
    {
      "id": 56,
      "query": "Design the database schema for encrypted real-time messaging.",
      "expected": "openrouter/anthropic/claude-opus-4.6",
      "routed_model": "unknown",
      "routed_models": [],
      "used_models": [],
      "correct_routing": false,
      "critical": false,
      "escalated": false,
      "latency_s": 2.892,
      "graph_latency_s": 0.0,
      "cost_usd": 0.0,
      "saved_vs_gpt5_usd": 0.012,
      "knn_top_score": 0.0,
      "flow_nodes": [],
      "can_self_answer": false,
      "failure_type": "runtime_error",
      "error": "litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.",
      "success": false
    }
  ]
}